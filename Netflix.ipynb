{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nterop": {
     "id": "827"
    }
   },
   "source": [
    "#### Preprocessing and evaluation are based on this [code](https://github.com/dawenl/vae_cf), and we complete the experiment of our paper by adding and modifying some here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nterop": {
     "id": "826"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import bottleneck as bn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nterop": {
     "id": "828"
    }
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location of the dataset\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480502</th>\n",
       "      <td>17770</td>\n",
       "      <td>1790158</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480503</th>\n",
       "      <td>17770</td>\n",
       "      <td>1608708</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480504</th>\n",
       "      <td>17770</td>\n",
       "      <td>234275</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480505</th>\n",
       "      <td>17770</td>\n",
       "      <td>255278</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480506</th>\n",
       "      <td>17770</td>\n",
       "      <td>453585</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100480507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movieId   userId  rating   timestamp\n",
       "0                1  1488844       3  2005-09-06\n",
       "1                1   822109       5  2005-05-13\n",
       "2                1   885013       4  2005-10-19\n",
       "3                1    30878       4  2005-12-26\n",
       "4                1   823519       3  2004-05-03\n",
       "...            ...      ...     ...         ...\n",
       "100480502    17770  1790158       4  2005-11-01\n",
       "100480503    17770  1608708       3  2005-07-19\n",
       "100480504    17770   234275       1  2004-08-07\n",
       "100480505    17770   255278       4  2004-05-28\n",
       "100480506    17770   453585       2  2005-03-10\n",
       "\n",
       "[100480507 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'Netflix.csv'), sep=',', names=['movieId', 'userId', 'rating', 'timestamp'])\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>893988</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1248029</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2238063</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480499</th>\n",
       "      <td>17770</td>\n",
       "      <td>365996</td>\n",
       "      <td>3</td>\n",
       "      <td>2003-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480501</th>\n",
       "      <td>17770</td>\n",
       "      <td>311124</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480503</th>\n",
       "      <td>17770</td>\n",
       "      <td>1608708</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480504</th>\n",
       "      <td>17770</td>\n",
       "      <td>234275</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480506</th>\n",
       "      <td>17770</td>\n",
       "      <td>453585</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43561317 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movieId   userId  rating   timestamp\n",
       "0                1  1488844       3  2005-09-06\n",
       "4                1   823519       3  2004-05-03\n",
       "5                1   893988       3  2005-11-17\n",
       "7                1  1248029       3  2004-04-22\n",
       "9                1  2238063       3  2005-05-11\n",
       "...            ...      ...     ...         ...\n",
       "100480499    17770   365996       3  2003-11-10\n",
       "100480501    17770   311124       3  2005-09-29\n",
       "100480503    17770  1608708       3  2005-07-19\n",
       "100480504    17770   234275       1  2004-08-07\n",
       "100480506    17770   453585       2  2005-03-10\n",
       "\n",
       "[43561317 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_for_negative = deepcopy(raw_data)\n",
    "raw_data_for_negative = raw_data_for_negative[raw_data_for_negative ['rating'] < 4]\n",
    "raw_data_for_negative\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>124105</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1842128</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480495</th>\n",
       "      <td>17770</td>\n",
       "      <td>1274035</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480498</th>\n",
       "      <td>17770</td>\n",
       "      <td>516110</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480500</th>\n",
       "      <td>17770</td>\n",
       "      <td>986348</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480502</th>\n",
       "      <td>17770</td>\n",
       "      <td>1790158</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480505</th>\n",
       "      <td>17770</td>\n",
       "      <td>255278</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56919190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movieId   userId  rating   timestamp\n",
       "1                1   822109       5  2005-05-13\n",
       "2                1   885013       4  2005-10-19\n",
       "3                1    30878       4  2005-12-26\n",
       "6                1   124105       4  2004-08-05\n",
       "8                1  1842128       4  2004-05-09\n",
       "...            ...      ...     ...         ...\n",
       "100480495    17770  1274035       4  2005-06-10\n",
       "100480498    17770   516110       5  2004-08-26\n",
       "100480500    17770   986348       4  2004-08-12\n",
       "100480502    17770  1790158       4  2005-11-01\n",
       "100480505    17770   255278       4  2004-05-28\n",
       "\n",
       "[56919190 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binarize the data (only keep ratings >= 4)\n",
    "raw_data = raw_data[raw_data['rating'] >= 4]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nterop": {
     "id": "833"
    }
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nterop": {
     "id": "834"
    }
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nterop": {
     "id": "835"
    }
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nterop": {
     "id": "836"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 56880037 watching events from 463435 users and 17769 movies (sparsity: 0.691%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nterop": {
     "id": "837"
    }
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nterop": {
     "id": "838"
    }
   },
   "outputs": [],
   "source": [
    "### create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nterop": {
     "id": "839"
    }
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nterop": {
     "id": "840"
    }
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nterop": {
     "id": "841"
    }
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nterop": {
     "id": "842"
    }
   },
   "outputs": [],
   "source": [
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nterop": {
     "id": "843"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "        \n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "            \n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nterop": {
     "id": "844"
    }
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nterop": {
     "id": "845"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>1116080</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>1664010</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1</td>\n",
       "      <td>767518</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "      <td>2413320</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>2569099</td>\n",
       "      <td>-1</td>\n",
       "      <td>2005-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480355</th>\n",
       "      <td>17770</td>\n",
       "      <td>187160</td>\n",
       "      <td>-1</td>\n",
       "      <td>2005-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480419</th>\n",
       "      <td>17770</td>\n",
       "      <td>635712</td>\n",
       "      <td>-1</td>\n",
       "      <td>2003-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480438</th>\n",
       "      <td>17770</td>\n",
       "      <td>172257</td>\n",
       "      <td>-1</td>\n",
       "      <td>2005-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480490</th>\n",
       "      <td>17770</td>\n",
       "      <td>635735</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480497</th>\n",
       "      <td>17770</td>\n",
       "      <td>834323</td>\n",
       "      <td>-1</td>\n",
       "      <td>2005-10-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1937764 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movieId   userId  rating   timestamp\n",
       "112              1  1116080       1  2005-08-08\n",
       "216              1  1664010       1  2005-10-12\n",
       "237              1   767518       1  2005-08-02\n",
       "263              1  2413320       1  2004-02-06\n",
       "328              1  2569099      -1  2005-08-16\n",
       "...            ...      ...     ...         ...\n",
       "100480355    17770   187160      -1  2005-01-23\n",
       "100480419    17770   635712      -1  2003-11-15\n",
       "100480438    17770   172257      -1  2005-03-14\n",
       "100480490    17770   635735       1  2004-12-01\n",
       "100480497    17770   834323      -1  2005-10-04\n",
       "\n",
       "[1937764 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vad_plays_negative = raw_data_for_negative.loc[raw_data_for_negative['userId'].isin(vd_users)]\n",
    "vad_plays_negative = vad_plays_negative.loc[vad_plays_negative['movieId'].isin(unique_sid)]\n",
    "vad_plays_negative['rating'].replace(1, -1.0, inplace=True)\n",
    "vad_plays_negative['rating'].replace(2, -1.0, inplace=True)\n",
    "vad_plays_negative['rating'].replace(3, -1.0, inplace=True)\n",
    "vad_plays_tr = pd.concat([vad_plays_tr, vad_plays_negative]).sort_index()\n",
    "vad_plays_tr['rating'].replace(4, 1.0, inplace=True)\n",
    "vad_plays_tr['rating'].replace(5, 1.0, inplace=True)\n",
    "vad_plays_tr\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nterop": {
     "id": "846"
    }
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nterop": {
     "id": "847"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_plays_negative = raw_data_for_negative.loc[raw_data_for_negative['userId'].isin(te_users)]\n",
    "test_plays_negative = test_plays_negative.loc[test_plays_negative['movieId'].isin(unique_sid)]\n",
    "test_plays_negative['rating'].replace(1, -1.0, inplace=True)\n",
    "test_plays_negative['rating'].replace(2, -1.0, inplace=True)\n",
    "test_plays_negative['rating'].replace(3, -1.0, inplace=True)\n",
    "test_plays_tr = pd.concat([test_plays_tr, test_plays_negative]).sort_index()\n",
    "test_plays_tr['rating'].replace(4, 1.0, inplace=True)\n",
    "test_plays_tr['rating'].replace(5, 1.0, inplace=True)\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
    "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
    "    rating = map(lambda x: x, tp['rating']) # We added this code for negative feedback experiment.\n",
    "    return pd.DataFrame(data={'uid': list(uid), 'sid': list(sid), 'rating': list(rating)}, columns=['uid', 'sid', 'rating']) # We modified this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-132a783f8aa5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_plays['rating'] = 1.0\n"
     ]
    }
   ],
   "source": [
    "train_plays['rating'] = 1.0\n",
    "vad_plays_te['rating'] = 1.0\n",
    "test_plays_te['rating'] = 1.0\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nterop": {
     "id": "849"
    }
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nterop": {
     "id": "850"
    }
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nterop": {
     "id": "851"
    }
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nterop": {
     "id": "852"
    }
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nterop": {
     "id": "853"
    }
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([ 1, -1]), array([1.]), array([-1,  1]), array([1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.rating.unique(), vad_data_tr.rating.unique(), vad_data_te.rating.unique(), test_data_tr.rating.unique(), test_data_te.rating.unique()\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nterop": {
     "id": "10"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nterop": {
     "id": "14"
    }
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((tp_tr['rating'], # We modified this code for negative feedback experiment.\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nterop": {
     "id": "857"
    }
   },
   "outputs": [],
   "source": [
    "### load training data\n",
    "X = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load validation data\n",
    "validation_data_tr, validation_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "    os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nterop": {
     "id": "857"
    }
   },
   "outputs": [],
   "source": [
    "### load test data\n",
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))\n",
    "\n",
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 1000\n",
    "G = X.T.dot(X).toarray()\n",
    "diagIndices = np.diag_indices(G.shape[0])\n",
    "G[diagIndices] += lambda_\n",
    "P = np.linalg.inv(G)\n",
    "B = P / (-np.diag(P))\n",
    "B[diagIndices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nterop": {
     "id": "24"
    }
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    \n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nterop": {
     "id": "25"
    }
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_EASE_for_validation(B, validation_data_tr, validation_data_te):\n",
    "    n100_list = []\n",
    "\n",
    "    Xvalidation = validation_data_tr\n",
    "    if sparse.isspmatrix(Xvalidation):\n",
    "        Xvalidation = Xvalidation.toarray()\n",
    "    Xvalidation = Xvalidation.astype('float32')\n",
    "    \n",
    "    pred_val = (Xvalidation).dot(B)\n",
    "    pred_val[Xvalidation.nonzero()] = -np.inf\n",
    "\n",
    "    n100_list.append(NDCG_binary_at_k_batch(pred_val, validation_data_te, k=100))\n",
    "    n100_list = np.concatenate(n100_list)\n",
    "    print(\"NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "    \n",
    "    return np.mean(n100_list)\n",
    "\n",
    "# We added this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_EASE(B, test_data_tr, test_data_te, step=2):\n",
    "    print(\"Evaluating on test set ...\")\n",
    "    n5_list, n10_list, n50_list, n100_list, r1_list, r5_list, r10_list, r20_list, r50_list, r100_list = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    Xtest = test_data_tr\n",
    "    if sparse.isspmatrix(Xtest):\n",
    "        Xtest = Xtest.toarray()\n",
    "    Xtest = Xtest.astype('float32')\n",
    "    \n",
    "    if step == 0:\n",
    "        Xtest[np.where(Xtest < 1)] = 0\n",
    "        pred_val = (Xtest).dot(B)\n",
    "        pred_val[Xtest.nonzero()] = -np.inf\n",
    "    \n",
    "    if step == 1:\n",
    "        Xtest[np.where(Xtest < 1)] = 0\n",
    "        pred_val = (Xtest).dot(B)\n",
    "        pred_val[test_data_tr.nonzero()] = -np.inf\n",
    "        \n",
    "    if step == 2:\n",
    "        pred_val = (Xtest).dot(B)\n",
    "        pred_val[Xtest.nonzero()] = -np.inf\n",
    "\n",
    "    n5_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te, k=5))\n",
    "    n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te, k=10))\n",
    "    n50_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te, k=50))\n",
    "    n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te, k=100))\n",
    "    r1_list.append(Recall_at_k_batch(pred_val, test_data_te, k=1))\n",
    "    r5_list.append(Recall_at_k_batch(pred_val, test_data_te, k=5))\n",
    "    r10_list.append(Recall_at_k_batch(pred_val, test_data_te, k=10))\n",
    "    r20_list.append(Recall_at_k_batch(pred_val, test_data_te, k=20))\n",
    "    r50_list.append(Recall_at_k_batch(pred_val, test_data_te, k=50))\n",
    "    r100_list.append(Recall_at_k_batch(pred_val, test_data_te, k=100))\n",
    "    \n",
    "    n5_list = np.concatenate(n5_list)\n",
    "    n10_list = np.concatenate(n10_list)\n",
    "    n50_list = np.concatenate(n50_list)\n",
    "    n100_list = np.concatenate(n100_list)\n",
    "    r1_list = np.concatenate(r1_list)\n",
    "    r5_list = np.concatenate(r5_list)\n",
    "    r10_list = np.concatenate(r10_list)\n",
    "    r20_list = np.concatenate(r20_list)\n",
    "    r50_list = np.concatenate(r50_list)\n",
    "    r100_list = np.concatenate(r100_list)\n",
    "    \n",
    "    print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "    print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "    print(\"Test Recall@10=%.5f (%.5f)\" % (np.mean(r10_list), np.std(r10_list) / np.sqrt(len(r10_list))))\n",
    "    print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "    print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))\n",
    "    print(\"Test Recall@100=%.5f (%.5f)\" % (np.mean(r100_list), np.std(r100_list) / np.sqrt(len(r100_list))))\n",
    "    print(\"Test NDCG@5=%.5f (%.5f)\" % (np.mean(n5_list), np.std(n5_list) / np.sqrt(len(n5_list))))\n",
    "    print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "    print(\"Test NDCG@50=%.5f (%.5f)\" % (np.mean(n50_list), np.std(n50_list) / np.sqrt(len(n50_list))))\n",
    "    print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "    \n",
    "# We modified this code for negative feedback experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE (base model)\n",
      "\n",
      "Evaluating on test set ...\n",
      "Test Recall@1=0.42820 (0.00495)\n",
      "Test Recall@5=0.35412 (0.00316)\n",
      "Test Recall@10=0.34384 (0.00278)\n",
      "Test Recall@20=0.36203 (0.00255)\n",
      "Test Recall@50=0.44528 (0.00248)\n",
      "Test Recall@100=0.55499 (0.00244)\n",
      "Test NDCG@5=0.36661 (0.00326)\n",
      "Test NDCG@10=0.34735 (0.00282)\n",
      "Test NDCG@50=0.35646 (0.00206)\n",
      "Test NDCG@100=0.39468 (0.00198)\n"
     ]
    }
   ],
   "source": [
    "# We added this code for negative feedback experiment.\n",
    "print('EASE (base model)\\n')\n",
    "evaluate_EASE(B, test_data_tr, test_data_te, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enf_EASE (Exclude negative feedback in ranking)\n",
      "\n",
      "Evaluating on test set ...\n",
      "Test Recall@1=0.46880 (0.00499)\n",
      "Test Recall@5=0.39896 (0.00341)\n",
      "Test Recall@10=0.38909 (0.00304)\n",
      "Test Recall@20=0.40446 (0.00277)\n",
      "Test Recall@50=0.48428 (0.00253)\n",
      "Test Recall@100=0.58910 (0.00241)\n",
      "Test NDCG@5=0.41040 (0.00348)\n",
      "Test NDCG@10=0.39169 (0.00308)\n",
      "Test NDCG@50=0.39744 (0.00228)\n",
      "Test NDCG@100=0.43365 (0.00217)\n"
     ]
    }
   ],
   "source": [
    "# We added this code for negative feedback experiment.\n",
    "print('Enf_EASE (Exclude negative feedback in ranking)\\n')\n",
    "evaluate_EASE(B, test_data_tr, test_data_te, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find optimal negative feedback weight alpha through validation\n",
      "\n",
      "alpha = -1\n",
      "NDCG@100=0.33766 (0.00212)\n",
      "\n",
      "alpha = -0.7\n",
      "NDCG@100=0.36413 (0.00214)\n",
      "\n",
      "alpha = -0.4\n",
      "NDCG@100=0.39477 (0.00216)\n",
      "\n",
      "alpha = -0.1\n",
      "NDCG@100=0.42508 (0.00217)\n",
      "\n",
      "alpha = 0.2\n",
      "NDCG@100=0.44581 (0.00219)\n",
      "\n",
      "alpha = 0.5\n",
      "NDCG@100=0.45064 (0.00220)\n",
      "\n",
      "alpha = 0.8\n",
      "NDCG@100=0.44315 (0.00217)\n",
      "\n",
      "alpha = 0.4\n",
      "NDCG@100=0.45086 (0.00221)\n",
      "\n",
      "alpha = 0.5\n",
      "NDCG@100=0.45064 (0.00220)\n",
      "\n",
      "alpha = 0.6\n",
      "NDCG@100=0.44930 (0.00220)\n",
      "\n",
      "optimal negative feedback weight alpha = 0.4\n"
     ]
    }
   ],
   "source": [
    "# We added this code for negative feedback experiment.\n",
    "print('find optimal negative feedback weight alpha through validation')\n",
    "\n",
    "sub_alpha = [-1, -0.7, -0.4, -0.1, 0.2, 0.5, 0.8]\n",
    "result = []\n",
    "for a in sub_alpha:\n",
    "    print('\\nalpha =', a)\n",
    "    sub_validation_data_tr = deepcopy(validation_data_tr)\n",
    "    sub_validation_data_tr = sub_validation_data_tr.toarray()\n",
    "    sub_validation_data_tr[np.where(sub_validation_data_tr < 0)] = a\n",
    "    result.append(evaluate_EASE_for_validation(B, sub_validation_data_tr, validation_data_te))\n",
    "    \n",
    "sub_maxi = sub_alpha[result.index(max(result))]\n",
    "sub_alpha = [sub_maxi-0.1, sub_maxi, sub_maxi+0.1]\n",
    "result = []\n",
    "for a in sub_alpha:\n",
    "    print('\\nalpha =', a)\n",
    "    sub_validation_data_tr = deepcopy(validation_data_tr)\n",
    "    sub_validation_data_tr = sub_validation_data_tr.toarray()\n",
    "    sub_validation_data_tr[np.where(sub_validation_data_tr < 0)] = a\n",
    "    result.append(evaluate_EASE_for_validation(B, sub_validation_data_tr, validation_data_te))\n",
    "    \n",
    "alpha = sub_alpha[result.index(max(result))]\n",
    "print('\\noptimal negative feedback weight alpha =', alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEnf_EASE (Use&Exclude negative feedback in raking)\n",
      "\n",
      "Evaluating on test set ...\n",
      "Test Recall@1=0.48540 (0.00500)\n",
      "Test Recall@5=0.41740 (0.00345)\n",
      "Test Recall@10=0.40591 (0.00309)\n",
      "Test Recall@20=0.42062 (0.00279)\n",
      "Test Recall@50=0.50248 (0.00253)\n",
      "Test Recall@100=0.60703 (0.00239)\n",
      "Test NDCG@5=0.42877 (0.00351)\n",
      "Test NDCG@10=0.40909 (0.00312)\n",
      "Test NDCG@50=0.41436 (0.00231)\n",
      "Test NDCG@100=0.45031 (0.00220)\n"
     ]
    }
   ],
   "source": [
    "# We added this code for negative feedback experiment.\n",
    "print('UEnf_EASE (Use&Exclude negative feedback in raking)\\n')\n",
    "test_data_tr = test_data_tr.toarray()\n",
    "test_data_tr[np.where(test_data_tr < 0)] = alpha\n",
    "test_data_tr = sparse.csr_matrix(test_data_tr)\n",
    "evaluate_EASE(B, test_data_tr, test_data_te, step=2)\n",
    "\n",
    "# This is our final model that we propose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nterop": {
   "seedId": "868"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
